{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065253d-e2b6-4d66-878e-918f2ad2891e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wqet_grader\n",
    "from IPython.display import VimeoVideo\n",
    "\n",
    "wqet_grader.init(\"Project 6 Assessment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2edea-4942-4669-ae00-3949828b010a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/SCFP2019.csv.gz\")\n",
    "print(\"df type:\", type(df))\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268b3fe-164f-4423-9c3a-d616a336d5d5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "mask = df[\"TURNFEAR\"] == 1\n",
    "df_fear = df[mask]\n",
    "print(\"df_fear type:\", type(df_fear))\n",
    "print(\"df_fear shape:\", df_fear.shape)\n",
    "df_fear.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63243218-489c-4f41-84c0-cdd82baadceb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "age_groups = df_fear[\"AGECL\"].unique()\n",
    "print(\"Age Groups:\", age_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8baa772-f5e4-452a-b2a7-a882f954628d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "agecl_dict = {\n",
    "    1: \"Under 35\",\n",
    "    2: \"35-44\",\n",
    "    3: \"45-54\",\n",
    "    4: \"55-64\",\n",
    "    5: \"65-74\",\n",
    "    6: \"75 or Older\",\n",
    "}\n",
    "\n",
    "age_cl = df_fear[\"AGECL\"].replace(agecl_dict)\n",
    "print(\"age_cl type:\", type(age_cl))\n",
    "print(\"age_cl shape:\", age_cl.shape)\n",
    "age_cl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a5030-957c-4b55-b9ce-93e186e0d586",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "age_cl_value_counts = age_cl.value_counts()\n",
    "\n",
    "# Bar plot of `age_cl_value_counts`\n",
    "age_cl_value_counts.plot(\n",
    "    kind=\"bar\",\n",
    "    xlabel=\"Age Group\",\n",
    "    ylabel=\"Frequency (count)\",\n",
    "    title=\"Credit Fearful: Age Groups\"\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f770fa02-948d-4b59-b80c-71f707b6e5a5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Plot histogram of \"AGE\"\n",
    "df_fear[\"AGE\"].hist(bins=10)\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency (count)\")\n",
    "plt.title(\"Credit Fearful: Age Distribution\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a69070-8323-4cd9-a908-ca369e05eed3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "race_dict = {\n",
    "    1: \"White/Non-Hispanic\",\n",
    "    2: \"Black/African-American\",\n",
    "    3: \"Hispanic\",\n",
    "    5: \"Other\",\n",
    "}\n",
    "race=df_fear[\"RACE\"].replace(race_dict)\n",
    "race_value_counts=race.value_counts(normalize=True)\n",
    "\n",
    "# Create bar chart of race_value_counts\n",
    "race_value_counts.plot(kind=\"barh\")\n",
    "plt.xlim((0, 1))\n",
    "plt.xlabel(\"Frequency (%)\")\n",
    "plt.ylabel(\"Race\")\n",
    "plt.title(\"Credit Fearful: Racial Groups\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f588f7-46eb-41e2-a474-0bdf8c7eb358",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "race = df[\"RACE\"].replace(race_dict)\n",
    "race_value_counts = race.value_counts(normalize=True)\n",
    "# Create bar chart of race_value_counts\n",
    "race_value_counts.plot(kind=\"barh\")\n",
    "plt.xlim((0, 1))\n",
    "plt.xlabel(\"Frequency (%)\")\n",
    "plt.ylabel(\"Race\")\n",
    "plt.title(\"SCF Respondents: Racial Groups\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7329b2d-171b-4836-b489-a2236716a2cd",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "inccat_dict = {\n",
    "    1: \"0-20\",\n",
    "    2: \"21-39.9\",\n",
    "    3: \"40-59.9\",\n",
    "    4: \"60-79.9\",\n",
    "    5: \"80-89.9\",\n",
    "    6: \"90-100\",\n",
    "}\n",
    "\n",
    "df_inccat = (\n",
    "    df[\"INCCAT\"]\n",
    "    .replace(inccat_dict)\n",
    "    .groupby(df[\"TURNFEAR\"])\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"frequency\")\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"df_inccat type:\", type(df_inccat))\n",
    "print(\"df_inccat shape:\", df_inccat.shape)\n",
    "df_inccat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaee0ec-7df9-4f61-b62f-e0cd6bc6cd3f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Create bar chart of `df_inccat`\n",
    "sns.barplot(\n",
    "    x=\"INCCAT\",\n",
    "    y=\"frequency\",\n",
    "    hue=\"TURNFEAR\",\n",
    "    data=df_inccat\n",
    ")\n",
    "plt.xlabel(\"Income Category\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.title(\"Income Distribution: Credit Fearful vs. Non-fearful\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3ef86-a45b-46bc-ab9d-446d196e49e6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "asset_house_corr = df[\"ASSET\"].corr(df[\"HOUSES\"])\n",
    "print(\"SCF: Asset Houses Correlation:\", asset_house_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636aa70a-dc7f-4c11-a766-65ebd8bfd234",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "asset_house_corr = df_fear[\"ASSET\"].corr(df_fear[\"HOUSES\"])\n",
    "print(\"Credit Fearful: Asset Houses Correlation:\", asset_house_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922d7f2-5f66-427e-8817-ad729e57d8a6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "cols = [\"ASSET\", \"HOUSES\", \"INCOME\", \"DEBT\", \"EDUC\"]\n",
    "corr = df[cols].corr()\n",
    "corr.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4be334f-a51e-48f1-a6b1-0d122f11c8ea",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "corr = df_fear[cols].corr()\n",
    "corr.style.background_gradient(axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d38d8c-f870-453f-b070-7f50dec6eba2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df_educ = (\n",
    "    df[\"EDUC\"]\n",
    "    .replace(inccat_dict)\n",
    "    .groupby(df[\"TURNFEAR\"])\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"frequency\")\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(\"df_educ type:\", type(df_educ))\n",
    "print(\"df_educ shape:\", df_educ.shape)\n",
    "df_educ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d86ef2-67b3-4686-8595-61e845db3a57",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(\n",
    "    x=\"EDUC\",\n",
    "    y=\"frequency\",\n",
    "    hue=\"TURNFEAR\",\n",
    "    data=df_educ\n",
    ")\n",
    "plt.xlabel(\"Education Level\")\n",
    "plt.ylabel(\"Frequency (%)\")\n",
    "plt.title(\"Educational Attainment: Credit Fearful vs. Non-fearful\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f616b4-f267-4671-9d8d-7a865c6878e3",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"DEBT\",y=\"ASSET\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a483f5-c9f6-40af-a009-7fef74fa696f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_fear.plot.scatter(x=\"DEBT\",y=\"ASSET\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a54b6-581b-4ad5-9fed-3db4b0678818",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"DEBT\",y=\"HOUSES\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c7a99-034f-4ffe-bc51-f13a10e7c5bf",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "df_fear.plot.scatter(x=\"DEBT\",y=\"HOUSES\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e39c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import wqet_grader\n",
    "from IPython.display import VimeoVideo\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from teaching_tools.widgets import ClusterWidget, SCFClusterWidget\n",
    "\n",
    "wqet_grader.init(\"Project 6 Assessment\")\n",
    "\n",
    "def wrangle(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    mask = df[\"TURNFEAR\"] == 1\n",
    "    df = df[mask]\n",
    "    return df\n",
    "df = wrangle(\"data/SCFP2019.csv.gz\")\n",
    "\n",
    "print(\"df type:\", type(df))\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# Plot \"HOUSES\" vs \"DEBT\"\n",
    "sns.scatterplot(x=(df[\"DEBT\"]/1e6), y=df[\"HOUSES\"])\n",
    "plt.xlabel(\"Household Debt [$1M]\")\n",
    "plt.ylabel(\"Home Value [$1M]\")\n",
    "plt.title(\"Credit Fearful: Home Value vs. Household Debt\");\n",
    "X = df[[\"DEBT\",\"HOUSES\"]]\n",
    "\n",
    "print(\"X type:\", type(X))\n",
    "print(\"X shape:\", X.shape)\n",
    "X.head()\n",
    "cw = ClusterWidget(n_clusters=3)\n",
    "cw.show()\n",
    "scfc = SCFClusterWidget(x=df[\"DEBT\"], y=df[\"HOUSES\"], n_clusters=3)\n",
    "scfc.show()\n",
    "\n",
    "## Build model\n",
    "model = KMeans(n_clusters=3,random_state=42)\n",
    "print(\"model type:\", type(model))\n",
    "\n",
    "model.fit(X)\n",
    "\n",
    "check_is_fitted(model)\n",
    "labels = model.labels_\n",
    "print(\"labels type:\", type(labels))\n",
    "print(\"labels shape:\", labels.shape)\n",
    "labels[:10]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=df[\"DEBT\"]/1e6,\n",
    "    y=df[\"HOUSES\"]/1e6,\n",
    "    hue=labels,\n",
    "    palette=\"deep\"\n",
    ")\n",
    "plt.xlabel(\"Household Debt [$1M]\")\n",
    "plt.ylabel(\"Home Value [$1M]\")\n",
    "plt.title(\"Credit Fearful: Home Value vs. Household Debt\");\n",
    "centroids = model.cluster_centers_\n",
    "print(\"centroids type:\", type(centroids))\n",
    "print(\"centroids shape:\", centroids.shape)\n",
    "centroids\n",
    "# Plot \"HOUSES\" vs \"DEBT\", add centroids\n",
    "sns.scatterplot(\n",
    "    x=df[\"DEBT\"]/1e6,\n",
    "    y=df[\"HOUSES\"]/1e6,\n",
    "    hue=labels,\n",
    "    palette=\"deep\"\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    x=centroids[:,0]/1e6,\n",
    "    y=centroids[:,1]/1e6,\n",
    "    color=\"gray\",\n",
    "    marker=\"*\",\n",
    "    s=150\n",
    "    \n",
    ")\n",
    "plt.xlabel(\"Household Debt [$1M]\")\n",
    "plt.ylabel(\"Home Value [$1M]\")\n",
    "plt.title(\"Credit Fearful: Home Value vs. Household Debt\");\n",
    "inertia = model.inertia_\n",
    "print(\"inertia type:\", type(inertia))\n",
    "print(\"Inertia (3 clusters):\", inertia)\n",
    "ss = silhouette_score(X, model.labels_)\n",
    "print(\"ss type:\", type(ss))\n",
    "print(\"Silhouette Score (3 clusters):\", ss)\n",
    "n_clusters = range(2,13)\n",
    "inertia_errors = []\n",
    "silhouette_scores = []\n",
    "\n",
    "# Add `for` loop to train model and calculate inertia, silhouette score.\n",
    "for k in n_clusters:\n",
    "    model = KMeans(n_clusters=k, random_state=42)\n",
    "    model.fit(X)\n",
    "    inertia_errors.append(model.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X,model.labels_))\n",
    "\n",
    "print(\"inertia_errors type:\", type(inertia_errors))\n",
    "print(\"inertia_errors len:\", len(inertia_errors))\n",
    "print(\"Inertia:\", inertia_errors)\n",
    "print()\n",
    "print(\"silhouette_scores type:\", type(silhouette_scores))\n",
    "print(\"silhouette_scores len:\", len(silhouette_scores))\n",
    "print(\"Silhouette Scores:\", silhouette_scores)\n",
    "# Plot `inertia_errors` by `n_clusters`\n",
    "plt.plot(n_clusters, inertia_errors)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"K-Means Model: Inertia vs Number of clusters\")\n",
    "\n",
    "# Plot `silhouette_scores` vs `n_clusters`\n",
    "plt.plot(n_clusters, silhouette_scores)\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"K-Means Model: Inertia vs Number of clusters\")\n",
    "\n",
    "# Build model\n",
    "final_model = KMeans(n_clusters=4,random_state=42)\n",
    "print(\"final_model type:\", type(final_model))\n",
    "\n",
    "# Fit model to data\n",
    "final_model.fit(X)\n",
    "\n",
    "# Assert that model has been fit to data\n",
    "check_is_fitted(final_model)\n",
    "# Plot \"HOUSES\" vs \"DEBT\" with final_model labels\n",
    "sns.scatterplot(\n",
    "    x=df[\"DEBT\"]/1e6,\n",
    "    y=df[\"HOUSES\"]/1e6,\n",
    "    hue=final_model.labels_,\n",
    "    palette=\"deep\"\n",
    "    \n",
    ")\n",
    "plt.xlabel(\"Household Debt [$1M]\")\n",
    "plt.ylabel(\"Home Value [$1M]\")\n",
    "plt.title(\"Credit Fearful: Home Value vs. Household Debt\");\n",
    "xgb = X.groupby(final_model.labels_).mean()\n",
    "\n",
    "print(\"xgb type:\", type(xgb))\n",
    "print(\"xgb shape:\", xgb.shape)\n",
    "xgb\n",
    "# Create side-by-side bar chart of `xgb`\n",
    "((xgb)/1e6).plot(kind=\"bar\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"Value [$1 million]\")\n",
    "plt.title(\"Mean Home Value & Household Debt by Cluster\");\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import wqet_grader\n",
    "from IPython.display import VimeoVideo\n",
    "from scipy.stats.mstats import trimmed_var\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "wqet_grader.init(\"Project 6 Assessment\")\n",
    "\n",
    "def wrangle(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    mask = (df[\"TURNFEAR\"] == 1) & (df[\"NETWORTH\"] < 2e6)\n",
    "    df = df[mask]\n",
    "    return df\n",
    "df = wrangle(\"data/SCFP2019.csv.gz\")\n",
    "\n",
    "print(\"df type:\", type(df))\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()\n",
    "# Calculate variance, get 10 largest features\n",
    "top_ten_var = df.var().sort_values().tail(10)\n",
    "\n",
    "print(\"top_ten_var type:\", type(top_ten_var))\n",
    "print(\"top_ten_var shape:\", top_ten_var.shape)\n",
    "top_ten_var\n",
    "# Create horizontal bar chart of `top_ten_var`\n",
    "fig = px.bar(\n",
    "    x=top_ten_var,\n",
    "    y=top_ten_var.index,\n",
    "    title=\"SCF: High Variance Features\"\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Variance\", yaxis_title=\"Feature\")\n",
    "fig.show()\n",
    "# Create a boxplot of `NHNFIN`\n",
    "fig = px.box(\n",
    "    data_frame=df,\n",
    "    x=\"NHNFIN\",\n",
    "    title=\"Distribution of Non-home, Non-Financial Assets\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# Calculate trimmed variance\n",
    "top_ten_trim_var = df.apply(trimmed_var, limits=(0.1, 0.1)).sort_values().tail(10)\n",
    "\n",
    "print(\"top_ten_trim_var type:\", type(top_ten_trim_var))\n",
    "print(\"top_ten_trim_var shape:\", top_ten_trim_var.shape)\n",
    "top_ten_trim_var\n",
    "# Create horizontal bar chart of `top_ten_trim_var`\n",
    "fig = px.bar(\n",
    "    x=top_ten_trim_var,\n",
    "    y=top_ten_trim_var.index,\n",
    "    title=\"SCF: High Variance Features\"\n",
    ")\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Trimmed Variance\", yaxis_title=\"Feature\")\n",
    "fig.show()\n",
    "high_var_cols = top_ten_trim_var.tail(5).index.to_list()\n",
    "\n",
    "print(\"high_var_cols type:\", type(high_var_cols))\n",
    "print(\"high_var_cols len:\", len(top_ten_trim_var))\n",
    "high_var_cols\n",
    "X = df[high_var_cols]\n",
    "\n",
    "print(\"X type:\", type(X))\n",
    "print(\"X shape:\", X.shape)\n",
    "X.head()\n",
    "X_summary = X.aggregate([\"mean\", \"std\"]).astype(int)\n",
    "\n",
    "print(\"X_summary type:\", type(X_summary))\n",
    "print(\"X_summary shape:\", X_summary.shape)\n",
    "X_summary\n",
    "# Instantiate transformer\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Transform `X`\n",
    "X_scaled_data = ss.fit_transform(X)\n",
    "\n",
    "# Put `X_scaled_data` into DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled_data, columns=X.columns)\n",
    "\n",
    "print(\"X_scaled type:\", type(X_scaled))\n",
    "print(\"X_scaled shape:\", X_scaled.shape)\n",
    "X_scaled.head()\n",
    "X_scaled_summary = X_scaled.aggregate([\"mean\", \"std\"]).astype(int)\n",
    "\n",
    "print(\"X_scaled_summary type:\", type(X_scaled_summary))\n",
    "print(\"X_scaled_summary shape:\", X_scaled_summary.shape)\n",
    "X_scaled_summary\n",
    "n_clusters = range(2,13)\n",
    "inertia_errors = []\n",
    "silhouette_scores = []\n",
    "\n",
    "# Add `for` loop to train model and calculate inertia, silhouette score.\n",
    "for k in n_clusters:\n",
    "    model = make_pipeline(StandardScaler(), KMeans(n_clusters=k, random_state=42))\n",
    "    model.fit(X)\n",
    "    inertia_errors.append(model.named_steps[\"kmeans\"].inertia_)\n",
    "    silhouette_scores.append(\n",
    "        silhouette_score(X, model.named_steps[\"kmeans\"].labels_)\n",
    "    )\n",
    "\n",
    "print(\"inertia_errors type:\", type(inertia_errors))\n",
    "print(\"inertia_errors len:\", len(inertia_errors))\n",
    "print(\"Inertia:\", inertia_errors[:3])\n",
    "print()\n",
    "print(\"silhouette_scores type:\", type(silhouette_scores))\n",
    "print(\"silhouette_scores len:\", len(silhouette_scores))\n",
    "print(\"Silhouette Scores:\", silhouette_scores[:3])\n",
    "# Create line plot of `inertia_errors` vs `n_clusters`\n",
    "fig = px.line(\n",
    "    x=n_clusters, y=inertia_errors, title=\"K-Means Model: Inertia vs Number of Clusters\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Number of Clusters\", yaxis_title=\"Inertia\")\n",
    "fig.show()\n",
    "# Create a line plot of `silhouette_scores` vs `n_clusters`\n",
    "fig = px.line(\n",
    "    x=n_clusters,\n",
    "    y=silhouette_scores,\n",
    "    title=\"K-Means Model: Silhouette Score vs Number of Clusters\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Number of Clusters\", yaxis_title=\"Silhouette Score\")\n",
    "fig.show()\n",
    "# Build model\n",
    "final_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KMeans(n_clusters=4, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit model to data\n",
    "final_model.fit(X)\n",
    "\n",
    "# Assert that model has been fit to data\n",
    "check_is_fitted(final_model)\n",
    "labels = final_model.named_steps[\"kmeans\"].labels_\n",
    "\n",
    "print(\"labels type:\", type(labels))\n",
    "print(\"labels len:\", len(labels))\n",
    "print(labels[:5])\n",
    "xgb = X.groupby(labels).mean()\n",
    "\n",
    "print(\"xgb type:\", type(xgb))\n",
    "print(\"xgb shape:\", xgb.shape)\n",
    "xgb\n",
    "# Create side-by-side bar chart of `xgb`\n",
    "fig = px.bar(\n",
    "    xgb,\n",
    "    barmode=\"group\",\n",
    "    title=\"Mean Household Finances by Cluster\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"Cluster\", yaxis_title=\"Value[$]\")\n",
    "fig.show()\n",
    "# Instantiate transformer\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "\n",
    "# Transform `X`\n",
    "X_t = pca.fit_transform(X)\n",
    "\n",
    "# Put `X_t` into DataFrame\n",
    "X_pca = pd.DataFrame(X_t, columns=(\"PC1\", \"PC2\"))\n",
    "\n",
    "print(\"X_pca type:\", type(X_pca))\n",
    "print(\"X_pca shape:\", X_pca.shape)\n",
    "X_pca.head()\n",
    "# Create scatter plot of `PC2` vs `PC1`\n",
    "fig = px.scatter(\n",
    "    data_frame=X_pca,\n",
    "    x=\"PC1\",\n",
    "    y=\"PC2\",\n",
    "    color=labels.astype(str),\n",
    "    title=\"PCA Representation of Clusters\"\n",
    ")\n",
    "fig.update_layout(xaxis_title=\"PC1\", yaxis_title=\"PC2\")\n",
    "fig.show()\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import wqet_grader\n",
    "from dash import Input, Output, dcc, html\n",
    "from IPython.display import VimeoVideo\n",
    "from jupyter_dash import JupyterDash\n",
    "from scipy.stats.mstats import trimmed_var\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "JupyterDash.infer_jupyter_proxy_config()\n",
    "from dash import jupyter_dash\n",
    "\n",
    "jupyter_dash.default_mode=\"external\"\n",
    "def wrangle(filepath):\n",
    "\n",
    "    \"\"\"Read SCF data file into ``DataFrame``.\n",
    "\n",
    "    Returns only credit fearful households whose net worth is less than $2 million.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        Location of CSV file.\n",
    "    \"\"\"\n",
    "    #load data\n",
    "    df = pd.read_csv(filepath)\n",
    "    #create mask\n",
    "    mask = (df[\"TURNFEAR\"] == 1) & (df[\"NETWORTH\"] < 2e6) \n",
    "    #subset dataframe\n",
    "    df = df[mask]\n",
    "    return df\n",
    "df = wrangle(\"data/SCFP2019.csv.gz\")\n",
    "\n",
    "print(\"df type:\", type(df))\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "print(\"app type:\", type(app)\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        #application title\n",
    "        html.H1(\"Survey of Consumer Finances\"),\n",
    "        #Bar chart element\n",
    "        html.H2(\"High Variance Features\"),\n",
    "        #bar chart graph\n",
    "        dcc.Graph(figure=serve_bar_chart(), id=\"bar-chart\"),\n",
    "        dcc.RadioItems(\n",
    "            options=[\n",
    "                {\"label\": \"trimmed\", \"value\": True},\n",
    "                {\"label\": \"not trimmed\", \"value\": False}\n",
    "            ],\n",
    "            value=True,\n",
    "            id=\"trim-button\"\n",
    "                \n",
    "        ),\n",
    "        html.H2(\"K-means clustering\"),\n",
    "        html.H3(\"Number of Clusters (k)\"),\n",
    "        dcc.Slider(min=2, max=12, step=1, value=2, id=\"k-slider\"),\n",
    "        html.Div(id=\"metrics\")\n",
    "    ]\n",
    ")\n",
    "def get_high_var_features(trimmed=True, return_feat_names=True):\n",
    "\n",
    "    \"\"\"Returns the five highest-variance features of ``df``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed : bool, default=True\n",
    "        If ``True``, calculates trimmed variance, removing bottom and top 10%\n",
    "        of observations.\n",
    "\n",
    "    return_feat_names : bool, default=False\n",
    "        If ``True``, returns feature names as a ``list``. If ``False``\n",
    "        returns ``Series``, where index is feature names and values are\n",
    "        variances.\n",
    "    \"\"\"\n",
    "    #calculate variance\n",
    "    if trimmed:\n",
    "        top_five_features = (\n",
    "        df.apply(trimmed_var).sort_values().tail(5)\n",
    "        )\n",
    "    else:\n",
    "        top_five_features = df.var().sort_values().tail(5)\n",
    "    \n",
    "    #extract names\n",
    "    if return_feat_names:\n",
    "        top_five_features = top_five_features.index.tolist()\n",
    "        \n",
    "    return top_five_features\n",
    "\n",
    "\n",
    "get_high_var_features()\n",
    "@app.callback(\n",
    "    Output(\"bar-chart\", \"figure\"), Input(\"trim-button\", \"value\")\n",
    ")\n",
    "def serve_bar_chart(trimmed=True):\n",
    "\n",
    "    \"\"\"Returns a horizontal bar chart of five highest-variance features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed : bool, default=True\n",
    "        If ``True``, calculates trimmed variance, removing bottom and top 10%\n",
    "        of observations.\n",
    "    \"\"\"\n",
    "    #Get features\n",
    "    top_five_features = get_high_var_features(trimmed=trimmed, return_feat_names=False)\n",
    "    \n",
    "    #bulid bar chart\n",
    "    fig = px.bar(x=top_five_features, y=top_five_features.index, orientation=\"h\")\n",
    "    fig.update_layout(xaxis_title=\"Variance\", yaxis_title=\"Feature\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "serve_bar_chart(trimmed=False)\n",
    "def get_model_metrics(trimmed=True, k=2, return_metrics=False):\n",
    "\n",
    "    \"\"\"Build ``KMeans`` model based on five highest-variance features in ``df``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed : bool, default=True\n",
    "        If ``True``, calculates trimmed variance, removing bottom and top 10%\n",
    "        of observations.\n",
    "\n",
    "    k : int, default=2\n",
    "        Number of clusters.\n",
    "\n",
    "    return_metrics : bool, default=False\n",
    "        If ``False`` returns ``KMeans`` model. If ``True`` returns ``dict``\n",
    "        with inertia and silhouette score.\n",
    "\n",
    "    \"\"\"\n",
    "    #get high var features\n",
    "    features = get_high_var_features(trimmed=trimmed, return_feat_names=True)\n",
    "    #create feature matrix\n",
    "    X = df[features]\n",
    "    #build model\n",
    "    model = make_pipeline(StandardScaler(), KMeans(n_clusters=k, random_state=42))\n",
    "    model.fit(X)\n",
    "    \n",
    "    if return_metrics:\n",
    "        #calculate inertia\n",
    "        i = model.named_steps[\"kmeans\"].inertia_\n",
    "        #calculate silhouette score\n",
    "        ss = silhouette_score(X, model.named_steps[\"kmeans\"].labels_)\n",
    "        #put results into dictionary\n",
    "        metrics = {\n",
    "            \"inertia\": round(i),\n",
    "            \"silhouette\": round(ss, 3)\n",
    "        }\n",
    "        #return dict to user\n",
    "        return metrics\n",
    "    return model\n",
    "get_model_metrics(trimmed=True, k=2, return_metrics=False)\n",
    "\n",
    "\n",
    "def serve_metrics(trimmed=True, k=2):\n",
    "\n",
    "    \"\"\"Returns list of ``H3`` elements containing inertia and silhouette score\n",
    "    for ``KMeans`` model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed : bool, default=True\n",
    "        If ``True``, calculates trimmed variance, removing bottom and top 10%\n",
    "        of observations.\n",
    "\n",
    "    k : int, default=2\n",
    "        Number of clusters.\n",
    "    \"\"\"\n",
    "    #get matrices\n",
    "    metrics = get_model_metrics(trimmed=trimmed, k=k, return_metrics=True)\n",
    "    #add metrices to html elements\n",
    "    text = [\n",
    "        html.H3(f\"Inertia: {metrics['inertia']}\"),\n",
    "        html.H3(f\"Silhouette Score: {metrics['silhouette']}\")    \n",
    "    ]\n",
    "    return text\n",
    "serve_metrics()\n",
    "def get_pca_labels(trimmed=True, k=2):\n",
    "\n",
    "    \"\"\"\n",
    "    ``KMeans`` labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed : bool, default=True\n",
    "        If ``True``, calculates trimmed variance, removing bottom and top 10%\n",
    "        of observations.\n",
    "\n",
    "    k : int, default=2\n",
    "        Number of clusters.\n",
    "    \"\"\"\n",
    "    #create feature matrix\n",
    "    features = get_high_var_features(trimmed=trimmed, return_feat_names=True)\n",
    "    X = df[features]\n",
    "    \n",
    "    #build transformer\n",
    "    transformer = PCA(n_components=2, random_state=42)\n",
    "    \n",
    "    #transform data\n",
    "    X_t = transformer.fit_transform(X)\n",
    "    X_pca = pd.DataFrame(X_t, columns=[\"PC1\", \"PC2\"])\n",
    "    \n",
    "    #add model\n",
    "    model = get_model_metrics(trimmed=trimmed, k=k, return_metrics=False)\n",
    "    X_pca[\"labels\"] = model.named_steps[\"kmeans\"].labels_.astype(str)\n",
    "    X_pca.sort_values(\"labels\", inplace=True)\n",
    "    return X_pca\n",
    "get_pca_labels().head()\n",
    "@app.callback(\n",
    "    Output(\"pca-scatter\", \"figure\"),\n",
    "    Input(\"trim-button\", \"value\"),\n",
    "    Input(\"k-slider\", \"value\")\n",
    ")\n",
    "def serve_scatter_plot(trimmed=True, k=2):\n",
    "\n",
    "    \"\"\"Build 2D scatter plot of ``df`` with ``KMeans`` labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trimmed : bool, default=True\n",
    "        If ``True``, calculates trimmed variance, removing bottom and top 10%\n",
    "        of observations.\n",
    "\n",
    "    k : int, default=2\n",
    "        Number of clusters.\n",
    "    \"\"\"\n",
    "    fig = px.scatter(\n",
    "        data_frame=get_pca_labels(trimmed=trimmed, k=k),\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        color=\"labels\",\n",
    "        title=\"PCA Representation of Clusters\"\n",
    "    \n",
    "    )\n",
    "    fig.update_layout(xaxis_title=\"PC1\", yaxis_title=\"PC2\")\n",
    "    return fig\n",
    "serve_scatter_plot(trimmed=False, k=6)\n",
    "app.run_server(host=\"0.0.0.0\", mode=\"external\")\n",
    "app.run(host=\"0.0.0.0\", mode=\"JupyterLab\")\n",
    "---\n",
    "Copyright 2023 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
